首先我们要理解为什么需要并发控制技术，如果我们需要一些的事物输入产生可串行化的执行结果，那么通常有两个思路。

- 逐个执行这些事务，这样我们所获得的结果当然是可串行化的。
- 并行的执行这些事务，但是保证结果是可串行化的。

第一种方法会将数据库之中的并发降低到 1，这显然在大部分系统中都是不能够被接受的，那么如何在并行执行、保证所需隔离性的要求下尽可能的提升并行度就是并发控制方法的目标。

<img src="https://littleneko.oss-cn-beijing.aliyuncs.com/img/1_4a773fe648.png" alt="1.png" style="zoom:50%;" />

<center>图 1 - 缺少并发控制方法导致的异常提交</center>

图 1 展示了在缺少并发控制方法的情况下，并行执行事务可能会带来异常的结果，图中 Txn2 将 Txn1 的写入结果覆盖，产生了 Lost update。

通常，所要求的隔离级别越高，系统整体的性能越低。

# 两阶段锁

两阶段锁的两个阶段分别是锁的扩张（Expanding）和收缩（Shrinking）阶段，而锁的类型又分为读锁和写锁，和常用的读写锁的功能对应。

![2.png](https://littleneko.oss-cn-beijing.aliyuncs.com/img/2_a18aff06bc.png)

<center>图2 - 两阶段锁的互斥表现</center>

图 2 中展示了加锁和遇到锁的情况，Txn3 在遇到了 Txn2 在 y 上的读锁时需要等待到 Txn2 结束才能够继续进行，而 Txn1 在遇到 Txn3 在 y 上的写锁时则需要等待到 Txn3 结束才能够继续进行。

除了标准的两阶段锁（2PL），还有一些更加严格的变种。标准的两阶段锁只要求锁的收缩阶段在扩张阶段之后，即在收缩阶段中不再申请新的锁即可，但是事务可能中锁收缩的过程中或是收缩结束之后仍然处于执行的状态。

<img src="https://littleneko.oss-cn-beijing.aliyuncs.com/img/3_8291ef5294.png" alt="3.png" style="zoom:50%;" />

<center>图 3 - 两阶段锁的互斥表现 bug</center>

图 3 是 2PL 与其两种变体 Strict 2PL(2PL) 和 Strong Strict 2PL(SS2PL) 的对比，2PL 只要求在锁申请结束后就可以释放锁，而 S2PL 要求事务执行结束后才允许释放写锁，SS2PL 则要求事务执行结束后才能够释放读锁和写锁。SS2PL 虽然是 2PL 的变体，但因为事务的执行只在扩张阶段中进行，实际上是一种一阶段锁。

<img src="https://littleneko.oss-cn-beijing.aliyuncs.com/img/24_0a203c84ef.jpg" alt="24.jpg" style="zoom:50%;" />

<center>表 1 - ANSI SQL 隔离级别的加锁要求</center>

表 1 是 ANSI SQL 隔离级别的加锁要求，对于脏写现象是否需要在读未提交的情况下被防止 ANSI SQL 中没有明确的说明，但是这一隔离级别在扩展的 ANSI SQL 中被列为最低的级别（ Degree 1），需要防止脏写，表中不作明确的说明。在读已提交下需要防止脏写，因此需要加写锁；而可重复读需要通过 item 上的读锁来防止读到的数据被其他事务所修改；可串行化则需要对 predicate 类型的查询添加读锁。

<img src="https://littleneko.oss-cn-beijing.aliyuncs.com/img/4_25782f5f5f.png" alt="4.png" style="zoom:50%;" />

<center>图 4 - Fuzzy Read(P2) 的现象</center>

两阶段锁的实现简单，但是对 SQL 隔离级别的影响却很深远，ANSI SQL 隔离级别以及它的扩展都是在两阶段锁的前提下制定的，在 “A Critique of ANSI SQL Isolation Levels” 中提出了一些在高隔离级别下读必须加锁理由。图 4 是 Fuzzy Read 的现象，论文声称因为没有加读锁导致事务两次读取到读数据违反了约束。

但如果站在现在的研究上回首，不难发现两阶段锁并不是唯一的并发控制方法，尝试用不同的方式去考虑这个问题，我们还有一些不依赖读写锁的并发控制方法。

# 乐观并发控制方法 - OCC

两阶段锁在事务的执行过程中通过加锁来保证隔离性，但是加锁是有 overhead 的，乐观的并发控制方法使用一种 lazy check 的机制，在事务执行过程中不加锁，在事务提交时候检查是否产生冲突。

<img src="https://littleneko.oss-cn-beijing.aliyuncs.com/img/5_4a5753d1b3.png" alt="5.png" style="zoom:50%;" />

<center>图5 - OCC 下的冲突</center>

图 5 是 OCC 下产生冲突的例子，因为 x 被修改，所以冲突事务必须回滚。但是 OCC 带来的问题就是在高冲突的场景下，频繁的发生事务回滚，会大幅影响系统的性能。

<img src="https://littleneko.oss-cn-beijing.aliyuncs.com/img/6_e28f816ab6.png" alt="6.png" style="zoom:50%;" />

<center>图6 - OCC 下的高冲突场景</center>

图 6 对比了 2PL 和 OCC 下的高冲突场景，可以看到高冲突场景下 2PL 的并发控制方法能够让事务逐个提交，但 OCC 会产生很多事务回滚，需要注意的是事务回滚也可能是有代价的，例如在 Percolator 的两阶段提交中，会在第一阶段发现事务冲突，因此在发现冲突的同时也会有一部分 prewrite 成功的数据，在清理这些数据的过程中，也需要消耗系统的性能。在冲突十分高的情况下，高频的回滚可能会阻塞系统的正常运行，因此 OCC 并不适用于这些使用场景。后文会详细讲述如何优化高冲突场景下的 OCC。

# 多版本并发控制方法 - MVCC

MVCC 是多版本并发控制方法，即对一份数据会存储多个版本，因此也需要一个 GC 去回收不再被使用的版本，释放系统的空间。

<img src="https://littleneko.oss-cn-beijing.aliyuncs.com/img/25_3afba3eed8.jpg" alt="25.jpg" style="zoom:50%;" />

<center>例 1 - MVCC 存储多版本的数据</center>

<img src="https://littleneko.oss-cn-beijing.aliyuncs.com/img/7_0ea094a19a.png" alt="7.png" style="zoom:50%;" />

<center>图7 - MVCC 中的异常</center>

图 7 是 MVCC 中的异常现象，在 MVCC 系统中，因为保存了历史数据，所以需要解决一个事务能读取到哪个。解决的常用办法是通过一个全局的版本分配器，版本会决定数据的可见性，在有些系统中，会将 timestamp 当作版本号，下文也用 ts 来代表版本，图中的 Txn2 使用 ts = 1 去读取，能读到 ts <= 1 的数据。即使在 Txn1 将数据写入之后，所写入到 ts = 2 的数据对于 Txn2 来说依旧是不可见的，所以 Txn2 不管使用 item read 还是 predicate read 都能够读到和之前相同的数据，防止了不可重复读或者幻读异常的发生。我们注意到在 2PL 的系统中，幻读被认为是不可重复读的延伸，存在两个原因，一是防止幻读需要范围读锁，比较难高效的实现（尤其是在分布式系统中）；二是防止幻读所需要的范围读锁，可能会严重影响系统的并发度。但是在多版本的系统中，只需要读取一个快照的数据，就能够同时防止不可重复读和幻读，因此将幻读列为不可重复读的延伸异常，就不是那么有道理了。

<img src="https://littleneko.oss-cn-beijing.aliyuncs.com/img/8_e2dd7c0dbe.png" alt="8.png" style="zoom:50%;" />

<center>图8 - MVCC 中的一致性问题</center>

MVCC 通过一个快照去读取相同的数据是一个很理想的想法，但是图 8 描述了 MVCC 中的一致性问题，如果一个事务在 Commit 过程中另一个事务用更新的 ts 进行读，那么对于尚未存在的数据，MVCC 无法正确处理，导致出现不可重复读的现象。

<img src="https://littleneko.oss-cn-beijing.aliyuncs.com/img/9_b2df1938b4.png" alt="9.png" style="zoom:50%;" />

<center>图9 - MVCC min_commit_ts 实现一致读</center>

为了解决这个图 8 的问题，MVCC 有两种办法，图 9 在系统中加入了一个约束，也是 TiDB 所使用的方法，写事务的 ts 必须大于所有与之相交的读事务，在实现中会让读事务推高 key 上的 min_commit_ts = read_ts + 1，在提交时候需要计算 commit_ts = max{commit_ts, min_commit_ts}，图 9 中，ts=2 的第一次读取将 min_commit_ts 推高到 3，进而让写事务写入的版本不影响 ts=2 的重复读取。感兴趣的同学还可以思考一下在 Percolator 提交协议下，predicate 读对于尚未存在的数据是如何防止幻读的。

> **TIPS**:
>
> 1. 这里所说的 TiDB 的解决方法应该只是在支持 [Async Commit](https://cn.pingcap.com/blog/async-commit-principle) 之后才需要的，因为在此之前 TiDB 的 commit_ts 是从 TSO 上取的，TSO 天然保证了取到的 timestamp 一定比当前所有的读 timestamp 要大，没有这个问题。(参考 https://asktug.com/t/topic/693814)（另外如果是基于 HLC 的实现，是需要解决这个问题的）
> 2. "Percolator 提交协议下，predicate 读对于尚未存在的数据是如何防止幻读的"：Percolator 在 prepare 时会加锁，因此上图中第一次读会阻塞，不会出现幻读的情况。

<img src="https://littleneko.oss-cn-beijing.aliyuncs.com/img/10_e2e41fa92c.png" alt="10.png" style="zoom:50%;" />

<center>图10 - MVCC safepoint 实现一致读</center>

图 10 是另一种解决方法，如果能知道全局的 safepoint，那么读事务只需要从 safepoint 进行读取，在 safepoint 之前的事务都已经被完整提交，这样就不会出现不一致的情况，后文的 MSTO 实现就是使用这个方式保证一致性的。

这两种方式的区别在于 min_commit_ts 不需要知道全局的事务信息，而 safepoint 需要但没有额外的开销，需要根据实际场景进行选择。

MVCC 最大的优点是读事务不需要阻塞写事务，相比于 2PL，在读写冲突的场景下，MVCC 能大幅提升并行度，但是 MVCC 自身也存在不可忽视的 overhead，在只需要单版本的场景下，会产生比较大的性能影响，同时 GC 可能会影响系统整体的稳定性，如带来延迟升高等。



----

https://cn.pingcap.com/blog/transaction-frontiers-research-article-talk4